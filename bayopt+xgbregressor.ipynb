{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAYESIAN OPTIMIZATION ON TOP XGB\n",
    "\n",
    "This notebook aims to introduce Bayesian Optimization as an alternative to traditional and very well known approaches like grid and random search. Bayesian Optimization can be used to optimize any black box function, which in this case will be the loss of a model as a function of the hyperparameters chosen.\n",
    "\n",
    "Let's first import the libraries needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import mquantiles\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset that will be used is an anonymized version of a real world website activity tracker. Numeric features contain masked numbers whose statistical relationship has been preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>CategoricalFeature1</th>\n",
       "      <th>CategoricalFeature2</th>\n",
       "      <th>Activity1</th>\n",
       "      <th>Activity2</th>\n",
       "      <th>Target</th>\n",
       "      <th>Activity3</th>\n",
       "      <th>Activity4</th>\n",
       "      <th>Activity5</th>\n",
       "      <th>Activity6</th>\n",
       "      <th>Activity7</th>\n",
       "      <th>Activity8</th>\n",
       "      <th>Activity9</th>\n",
       "      <th>Activity10</th>\n",
       "      <th>Activity11</th>\n",
       "      <th>Activity12</th>\n",
       "      <th>Activity13</th>\n",
       "      <th>Activity14</th>\n",
       "      <th>Activity15</th>\n",
       "      <th>Activity16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4684.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>7475.0</td>\n",
       "      <td>3816.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>544.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>Cat_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>962.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6623.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Cat_3</td>\n",
       "      <td>Cat_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>Cat_11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date CategoricalFeature1 CategoricalFeature2  Activity1  Activity2  \\\n",
       "0  1/1/2015               Cat_1               Cat_1        NaN     4684.0   \n",
       "1  1/1/2015               Cat_3               Cat_1        NaN     1247.0   \n",
       "2  1/1/2015               Cat_1              Cat_10        NaN      962.0   \n",
       "3  1/1/2015               Cat_3              Cat_10        NaN      437.0   \n",
       "4  1/1/2015               Cat_1              Cat_11        NaN       43.0   \n",
       "\n",
       "   Target  Activity3  Activity4  Activity5  Activity6  Activity7  Activity8  \\\n",
       "0    64.0     2388.0     4361.0        NaN        NaN     3917.0        NaN   \n",
       "1    71.0      611.0     1182.0        NaN        NaN     1061.0        NaN   \n",
       "2    59.0      617.0     1862.0        NaN        NaN     6623.0        NaN   \n",
       "3    48.0      262.0      761.0        NaN        NaN     3075.0        NaN   \n",
       "4     NaN       30.0       43.0        NaN        NaN       42.0        NaN   \n",
       "\n",
       "   Activity9  Activity10  Activity11  Activity12  Activity13  Activity14  \\\n",
       "0     1403.0      2514.0      5575.0      7475.0      3816.0         NaN   \n",
       "1      408.0       723.0      1724.0      2440.0      1060.0         NaN   \n",
       "2      365.0       399.0      1174.0      1679.0       750.0         NaN   \n",
       "3      158.0       222.0       415.0       656.0       340.0         NaN   \n",
       "4        NaN        30.0        29.0        30.0        29.0         NaN   \n",
       "\n",
       "   Activity15  Activity16  \n",
       "0      2894.0         NaN  \n",
       "1       544.0         NaN  \n",
       "2       292.0         NaN  \n",
       "3       167.0         NaN  \n",
       "4        27.0         NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('website-train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering in this use case will be simplified to retain the focus put on applying Bayesian Optimization. Only numeric features will be kept. Missing values will be kept in all cases. Missing observations in the target variable will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity1</th>\n",
       "      <th>Activity2</th>\n",
       "      <th>Target</th>\n",
       "      <th>Activity3</th>\n",
       "      <th>Activity4</th>\n",
       "      <th>Activity5</th>\n",
       "      <th>Activity6</th>\n",
       "      <th>Activity7</th>\n",
       "      <th>Activity8</th>\n",
       "      <th>Activity9</th>\n",
       "      <th>Activity10</th>\n",
       "      <th>Activity11</th>\n",
       "      <th>Activity12</th>\n",
       "      <th>Activity13</th>\n",
       "      <th>Activity14</th>\n",
       "      <th>Activity15</th>\n",
       "      <th>Activity16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4684.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>7475.0</td>\n",
       "      <td>3816.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>544.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>962.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>1862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6623.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>292.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>437.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>66192.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>16092.0</td>\n",
       "      <td>47437.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47763.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14012.0</td>\n",
       "      <td>41778.0</td>\n",
       "      <td>130170.0</td>\n",
       "      <td>171597.0</td>\n",
       "      <td>71765.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41454.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity1  Activity2  Target  Activity3  Activity4  Activity5  Activity6  \\\n",
       "0        NaN     4684.0    64.0     2388.0     4361.0        NaN        NaN   \n",
       "1        NaN     1247.0    71.0      611.0     1182.0        NaN        NaN   \n",
       "2        NaN      962.0    59.0      617.0     1862.0        NaN        NaN   \n",
       "3        NaN      437.0    48.0      262.0      761.0        NaN        NaN   \n",
       "5        NaN    66192.0   485.0    16092.0    47437.0        NaN        NaN   \n",
       "\n",
       "   Activity7  Activity8  Activity9  Activity10  Activity11  Activity12  \\\n",
       "0     3917.0        NaN     1403.0      2514.0      5575.0      7475.0   \n",
       "1     1061.0        NaN      408.0       723.0      1724.0      2440.0   \n",
       "2     6623.0        NaN      365.0       399.0      1174.0      1679.0   \n",
       "3     3075.0        NaN      158.0       222.0       415.0       656.0   \n",
       "5    47763.0        NaN    14012.0     41778.0    130170.0    171597.0   \n",
       "\n",
       "   Activity13  Activity14  Activity15  Activity16  \n",
       "0      3816.0         NaN      2894.0         NaN  \n",
       "1      1060.0         NaN       544.0         NaN  \n",
       "2       750.0         NaN       292.0         NaN  \n",
       "3       340.0         NaN       167.0         NaN  \n",
       "5     71765.0         NaN     41454.0         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out missing values in target and filling missings\n",
    "df = df.dropna(subset = ['Target'])\n",
    "\n",
    "to_drop = ['Date', 'CategoricalFeature1', 'CategoricalFeature2']\n",
    "df = df.drop(to_drop, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Steps\n",
    "\n",
    "Before moving on, we need to separate our data set between X and y and then generate training and testing sets. Finally, the result of that will be encapsulated into XGB DMatrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df.Target\n",
    "\n",
    "# Splitting into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Saving memory and moving datasets to the xgb structure\n",
    "del(df)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "del(X_train)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "del(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bayesian Optimization\n",
    "\n",
    "A visual demo of how Bayesian Optimization works can be found below. We are going to replicate this idea with our data set. To add some context, we are going to use XGBRegressor as our main prediction model. A priori, we cannot have certainty about which could be the optimal combination of hyperparameters. We do have some guidance about which hyperparameter ranges could lead to better results, but finding the optimal combination of them is impossible in practice without taking a smarter approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](bayesian.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to define a function that will take all the hyperparameters we are going to optimize after. We will use that set of parameters and our previously created DMatrix to apply cross validation with 3 folds. Bayesian Optimization is a maximizer so we need to do a minor tweaking for it to minimize our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, learning_rate, gamma, min_child_weight, colsample_bytree):\n",
    "    \n",
    "    params = {'eval_metric': 'rmse',\n",
    "              'max_depth': int(max_depth),\n",
    "              'learning_rate': float(learning_rate),\n",
    "              'gamma': float(gamma),\n",
    "              'min_child_weight': int(min_child_weight),\n",
    "              'colsample_bytree': float(colsample_bytree),\n",
    "              'subsample': 0.8,}\n",
    "    \n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n",
    "    \n",
    "    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n",
    "    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, optimization can begin (performance is the y of the function and the idea is to minimize error). We are going to define ranges of values for each hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-102.5   \u001b[0m | \u001b[0m 0.4548  \u001b[0m | \u001b[0m 0.3899  \u001b[0m | \u001b[0m 0.1097  \u001b[0m | \u001b[0m 3.514   \u001b[0m | \u001b[0m 3.287   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-106.3   \u001b[0m | \u001b[0m 0.5647  \u001b[0m | \u001b[0m 0.6391  \u001b[0m | \u001b[0m 0.3519  \u001b[0m | \u001b[0m 4.817   \u001b[0m | \u001b[0m 9.787   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-104.7   \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 0.9871  \u001b[0m | \u001b[0m 0.219   \u001b[0m | \u001b[0m 10.94   \u001b[0m | \u001b[0m 5.603   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-103.4   \u001b[0m | \u001b[0m 0.5876  \u001b[0m | \u001b[0m 0.2525  \u001b[0m | \u001b[0m 0.2667  \u001b[0m | \u001b[0m 3.266   \u001b[0m | \u001b[0m 3.622   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-103.2   \u001b[0m | \u001b[0m 0.7448  \u001b[0m | \u001b[0m 0.3726  \u001b[0m | \u001b[0m 0.2761  \u001b[0m | \u001b[0m 6.674   \u001b[0m | \u001b[0m 1.004   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-105.3   \u001b[0m | \u001b[0m 0.6391  \u001b[0m | \u001b[0m 0.1182  \u001b[0m | \u001b[0m 0.3183  \u001b[0m | \u001b[0m 6.538   \u001b[0m | \u001b[0m 4.849   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-105.8   \u001b[0m | \u001b[0m 0.7893  \u001b[0m | \u001b[0m 0.3463  \u001b[0m | \u001b[0m 0.4129  \u001b[0m | \u001b[0m 3.338   \u001b[0m | \u001b[0m 9.899   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-103.2   \u001b[0m | \u001b[0m 0.626   \u001b[0m | \u001b[0m 0.4017  \u001b[0m | \u001b[0m 0.2722  \u001b[0m | \u001b[0m 4.585   \u001b[0m | \u001b[0m 3.514   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m-102.1   \u001b[0m | \u001b[95m 0.6956  \u001b[0m | \u001b[95m 0.8114  \u001b[0m | \u001b[95m 0.2432  \u001b[0m | \u001b[95m 4.781   \u001b[0m | \u001b[95m 5.785   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-103.9   \u001b[0m | \u001b[0m 0.4144  \u001b[0m | \u001b[0m 0.1222  \u001b[0m | \u001b[0m 0.2144  \u001b[0m | \u001b[0m 3.727   \u001b[0m | \u001b[0m 8.496   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-102.9   \u001b[0m | \u001b[0m 0.6697  \u001b[0m | \u001b[0m 0.9154  \u001b[0m | \u001b[0m 0.2014  \u001b[0m | \u001b[0m 4.433   \u001b[0m | \u001b[0m 5.784   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-105.6   \u001b[0m | \u001b[0m 0.7452  \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 0.2974  \u001b[0m | \u001b[0m 5.041   \u001b[0m | \u001b[0m 5.922   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-107.4   \u001b[0m | \u001b[0m 0.4007  \u001b[0m | \u001b[0m 0.5957  \u001b[0m | \u001b[0m 0.3248  \u001b[0m | \u001b[0m 6.484   \u001b[0m | \u001b[0m 5.857   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-106.0   \u001b[0m | \u001b[0m 0.4222  \u001b[0m | \u001b[0m 0.4719  \u001b[0m | \u001b[0m 0.3246  \u001b[0m | \u001b[0m 7.508   \u001b[0m | \u001b[0m 4.955   \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m-99.72   \u001b[0m | \u001b[95m 0.4647  \u001b[0m | \u001b[95m 0.7193  \u001b[0m | \u001b[95m 0.08433 \u001b[0m | \u001b[95m 6.208   \u001b[0m | \u001b[95m 4.152   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-101.4   \u001b[0m | \u001b[0m 0.7189  \u001b[0m | \u001b[0m 0.3016  \u001b[0m | \u001b[0m 0.1397  \u001b[0m | \u001b[0m 6.443   \u001b[0m | \u001b[0m 9.369   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-103.5   \u001b[0m | \u001b[0m 0.5732  \u001b[0m | \u001b[0m 0.7944  \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 3.175   \u001b[0m | \u001b[0m 5.799   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-109.0   \u001b[0m | \u001b[0m 0.7279  \u001b[0m | \u001b[0m 0.8145  \u001b[0m | \u001b[0m 0.4851  \u001b[0m | \u001b[0m 5.372   \u001b[0m | \u001b[0m 2.869   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-104.2   \u001b[0m | \u001b[0m 0.5927  \u001b[0m | \u001b[0m 0.01527 \u001b[0m | \u001b[0m 0.2633  \u001b[0m | \u001b[0m 6.742   \u001b[0m | \u001b[0m 9.658   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-105.4   \u001b[0m | \u001b[0m 0.7607  \u001b[0m | \u001b[0m 0.5575  \u001b[0m | \u001b[0m 0.2989  \u001b[0m | \u001b[0m 7.121   \u001b[0m | \u001b[0m 4.634   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-109.4   \u001b[0m | \u001b[0m 0.5916  \u001b[0m | \u001b[0m 0.04444 \u001b[0m | \u001b[0m 0.3862  \u001b[0m | \u001b[0m 8.514   \u001b[0m | \u001b[0m 1.333   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-102.8   \u001b[0m | \u001b[0m 0.6349  \u001b[0m | \u001b[0m 0.8004  \u001b[0m | \u001b[0m 0.2345  \u001b[0m | \u001b[0m 4.029   \u001b[0m | \u001b[0m 2.368   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-105.3   \u001b[0m | \u001b[0m 0.6598  \u001b[0m | \u001b[0m 0.2299  \u001b[0m | \u001b[0m 0.2848  \u001b[0m | \u001b[0m 7.854   \u001b[0m | \u001b[0m 7.019   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-106.5   \u001b[0m | \u001b[0m 0.5442  \u001b[0m | \u001b[0m 0.06608 \u001b[0m | \u001b[0m 0.4026  \u001b[0m | \u001b[0m 5.487   \u001b[0m | \u001b[0m 8.601   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-103.6   \u001b[0m | \u001b[0m 0.534   \u001b[0m | \u001b[0m 0.08845 \u001b[0m | \u001b[0m 0.2018  \u001b[0m | \u001b[0m 10.97   \u001b[0m | \u001b[0m 9.704   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-108.8   \u001b[0m | \u001b[0m 0.681   \u001b[0m | \u001b[0m 0.8652  \u001b[0m | \u001b[0m 0.4968  \u001b[0m | \u001b[0m 4.228   \u001b[0m | \u001b[0m 5.054   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-103.4   \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 0.4186  \u001b[0m | \u001b[0m 0.2345  \u001b[0m | \u001b[0m 8.618   \u001b[0m | \u001b[0m 3.548   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-102.6   \u001b[0m | \u001b[0m 0.468   \u001b[0m | \u001b[0m 0.4086  \u001b[0m | \u001b[0m 0.09653 \u001b[0m | \u001b[0m 3.646   \u001b[0m | \u001b[0m 1.548   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-113.3   \u001b[0m | \u001b[0m 0.4088  \u001b[0m | \u001b[0m 0.2842  \u001b[0m | \u001b[0m 0.4788  \u001b[0m | \u001b[0m 10.78   \u001b[0m | \u001b[0m 1.965   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-106.4   \u001b[0m | \u001b[0m 0.7586  \u001b[0m | \u001b[0m 0.1403  \u001b[0m | \u001b[0m 0.3853  \u001b[0m | \u001b[0m 5.592   \u001b[0m | \u001b[0m 1.11    \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-104.5   \u001b[0m | \u001b[0m 0.5288  \u001b[0m | \u001b[0m 0.82    \u001b[0m | \u001b[0m 0.2569  \u001b[0m | \u001b[0m 6.291   \u001b[0m | \u001b[0m 4.084   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-105.4   \u001b[0m | \u001b[0m 0.5197  \u001b[0m | \u001b[0m 0.8531  \u001b[0m | \u001b[0m 0.2905  \u001b[0m | \u001b[0m 6.295   \u001b[0m | \u001b[0m 4.087   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-99.95   \u001b[0m | \u001b[0m 0.658   \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 0.0683  \u001b[0m | \u001b[0m 5.353   \u001b[0m | \u001b[0m 2.146   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-106.8   \u001b[0m | \u001b[0m 0.5651  \u001b[0m | \u001b[0m 0.2167  \u001b[0m | \u001b[0m 0.4014  \u001b[0m | \u001b[0m 4.639   \u001b[0m | \u001b[0m 7.873   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-103.1   \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.9465  \u001b[0m | \u001b[0m 0.1854  \u001b[0m | \u001b[0m 10.52   \u001b[0m | \u001b[0m 5.542   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-106.9   \u001b[0m | \u001b[0m 0.6029  \u001b[0m | \u001b[0m 0.6892  \u001b[0m | \u001b[0m 0.4121  \u001b[0m | \u001b[0m 5.141   \u001b[0m | \u001b[0m 2.043   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-110.1   \u001b[0m | \u001b[0m 0.4906  \u001b[0m | \u001b[0m 0.9483  \u001b[0m | \u001b[0m 0.4723  \u001b[0m | \u001b[0m 5.42    \u001b[0m | \u001b[0m 2.054   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-105.5   \u001b[0m | \u001b[0m 0.5438  \u001b[0m | \u001b[0m 0.4262  \u001b[0m | \u001b[0m 0.3404  \u001b[0m | \u001b[0m 4.372   \u001b[0m | \u001b[0m 9.272   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-101.3   \u001b[0m | \u001b[0m 0.4249  \u001b[0m | \u001b[0m 0.5103  \u001b[0m | \u001b[0m 0.114   \u001b[0m | \u001b[0m 5.156   \u001b[0m | \u001b[0m 3.723   \u001b[0m |\n",
      "| \u001b[95m 40      \u001b[0m | \u001b[95m-99.59   \u001b[0m | \u001b[95m 0.7418  \u001b[0m | \u001b[95m 0.711   \u001b[0m | \u001b[95m 0.06636 \u001b[0m | \u001b[95m 9.951   \u001b[0m | \u001b[95m 4.776   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-101.7   \u001b[0m | \u001b[0m 0.7761  \u001b[0m | \u001b[0m 0.4371  \u001b[0m | \u001b[0m 0.1454  \u001b[0m | \u001b[0m 4.11    \u001b[0m | \u001b[0m 2.411   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-105.2   \u001b[0m | \u001b[0m 0.4826  \u001b[0m | \u001b[0m 0.5979  \u001b[0m | \u001b[0m 0.3139  \u001b[0m | \u001b[0m 7.35    \u001b[0m | \u001b[0m 2.268   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-107.2   \u001b[0m | \u001b[0m 0.6628  \u001b[0m | \u001b[0m 0.6582  \u001b[0m | \u001b[0m 0.31    \u001b[0m | \u001b[0m 8.159   \u001b[0m | \u001b[0m 8.457   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-104.5   \u001b[0m | \u001b[0m 0.6529  \u001b[0m | \u001b[0m 0.9822  \u001b[0m | \u001b[0m 0.2718  \u001b[0m | \u001b[0m 7.669   \u001b[0m | \u001b[0m 8.264   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-105.1   \u001b[0m | \u001b[0m 0.6268  \u001b[0m | \u001b[0m 0.3874  \u001b[0m | \u001b[0m 0.3475  \u001b[0m | \u001b[0m 7.6     \u001b[0m | \u001b[0m 2.295   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-100.6   \u001b[0m | \u001b[0m 0.7386  \u001b[0m | \u001b[0m 0.6443  \u001b[0m | \u001b[0m 0.09602 \u001b[0m | \u001b[0m 5.43    \u001b[0m | \u001b[0m 8.491   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-104.3   \u001b[0m | \u001b[0m 0.7212  \u001b[0m | \u001b[0m 0.6934  \u001b[0m | \u001b[0m 0.3215  \u001b[0m | \u001b[0m 3.63    \u001b[0m | \u001b[0m 9.415   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-107.1   \u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.9146  \u001b[0m | \u001b[0m 0.2995  \u001b[0m | \u001b[0m 10.66   \u001b[0m | \u001b[0m 6.726   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-106.8   \u001b[0m | \u001b[0m 0.7861  \u001b[0m | \u001b[0m 0.2118  \u001b[0m | \u001b[0m 0.3889  \u001b[0m | \u001b[0m 5.013   \u001b[0m | \u001b[0m 9.687   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-104.5   \u001b[0m | \u001b[0m 0.6017  \u001b[0m | \u001b[0m 0.1972  \u001b[0m | \u001b[0m 0.2462  \u001b[0m | \u001b[0m 6.713   \u001b[0m | \u001b[0m 6.66    \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-105.3   \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.9988  \u001b[0m | \u001b[0m 0.2497  \u001b[0m | \u001b[0m 8.934   \u001b[0m | \u001b[0m 1.504   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-102.1   \u001b[0m | \u001b[0m 0.5906  \u001b[0m | \u001b[0m 0.8849  \u001b[0m | \u001b[0m 0.1572  \u001b[0m | \u001b[0m 3.438   \u001b[0m | \u001b[0m 7.898   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-100.2   \u001b[0m | \u001b[0m 0.7507  \u001b[0m | \u001b[0m 0.7832  \u001b[0m | \u001b[0m 0.09309 \u001b[0m | \u001b[0m 4.195   \u001b[0m | \u001b[0m 2.053   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-102.5   \u001b[0m | \u001b[0m 0.5468  \u001b[0m | \u001b[0m 0.7786  \u001b[0m | \u001b[0m 0.1761  \u001b[0m | \u001b[0m 9.485   \u001b[0m | \u001b[0m 1.343   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-103.3   \u001b[0m | \u001b[0m 0.6727  \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 0.214   \u001b[0m | \u001b[0m 7.214   \u001b[0m | \u001b[0m 8.546   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-104.4   \u001b[0m | \u001b[0m 0.5671  \u001b[0m | \u001b[0m 0.8229  \u001b[0m | \u001b[0m 0.301   \u001b[0m | \u001b[0m 3.758   \u001b[0m | \u001b[0m 7.95    \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-113.4   \u001b[0m | \u001b[0m 0.6485  \u001b[0m | \u001b[0m 0.524   \u001b[0m | \u001b[0m 0.4681  \u001b[0m | \u001b[0m 9.046   \u001b[0m | \u001b[0m 9.286   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-102.2   \u001b[0m | \u001b[0m 0.7235  \u001b[0m | \u001b[0m 0.9693  \u001b[0m | \u001b[0m 0.1772  \u001b[0m | \u001b[0m 5.25    \u001b[0m | \u001b[0m 2.195   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-102.0   \u001b[0m | \u001b[0m 0.7211  \u001b[0m | \u001b[0m 0.7929  \u001b[0m | \u001b[0m 0.1322  \u001b[0m | \u001b[0m 10.07   \u001b[0m | \u001b[0m 4.748   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-101.1   \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 0.7061  \u001b[0m | \u001b[0m 0.1454  \u001b[0m | \u001b[0m 5.874   \u001b[0m | \u001b[0m 9.938   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 11),\n",
    "                                             'learning_rate': (0.05, 0.5),\n",
    "                                             'gamma': (0, 1),\n",
    "                                             'min_child_weight': (1, 10),\n",
    "                                             'colsample_bytree': (0.4, 0.8)})\n",
    "\n",
    "# Use the expected improvement acquisition function to handle negative numbers\n",
    "# init and iter can be lower\n",
    "xgb_bo.maximize(init_points=10, n_iter=50, acq='ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7418139052555597, 'gamma': 0.7110264022048283, 'learning_rate': 0.06635929713655503, 'max_depth': 9, 'min_child_weight': 4}\n"
     ]
    }
   ],
   "source": [
    "# Get the best params from bayesian\n",
    "params = xgb_bo.max['params']\n",
    "\n",
    "# Set to int if floats\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "params['min_child_weight'] = int(params['min_child_weight'])\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the optimization process is a set of optimal hyperparameters. That is, the hyperparameters that through Bayesian Optimization were found as the ones minimizing the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training With Optimal Hyperparameters\n",
    "\n",
    "As the optimal hyperparameters are now known, let's use them to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.73812986706827\n",
      "35.65469181340354\n"
     ]
    }
   ],
   "source": [
    "# Train a new model with the best parameters from the search\n",
    "model = xgb.train(params, dtrain, num_boost_round=250)\n",
    "\n",
    "# Predict on testing and training set\n",
    "y_pred = model.predict(dtest)\n",
    "y_train_pred = model.predict(dtrain)\n",
    "\n",
    "# Report testing and training RMSE\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(np.sqrt(mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an additional step, fscores for each predictor can be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21d9b944648>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fscores = pd.DataFrame({'X': list(model.get_fscore().keys()), 'Y': list(model.get_fscore().values())})\n",
    "fscores.sort_values(by='Y').plot.bar(x='X');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Over Holdout Set\n",
    "\n",
    "Up to this stage, we have run our procedure using a single data set that was separated into training and testing frames. A mandatory and final step to corroborate that results can be generalized is to introduce a holdout set with observations the model has never seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>CategoricalFeature1</th>\n",
       "      <th>CategoricalFeature2</th>\n",
       "      <th>Activity1</th>\n",
       "      <th>Activity2</th>\n",
       "      <th>Target</th>\n",
       "      <th>Activity3</th>\n",
       "      <th>Activity4</th>\n",
       "      <th>Activity5</th>\n",
       "      <th>Activity6</th>\n",
       "      <th>Activity7</th>\n",
       "      <th>Activity8</th>\n",
       "      <th>Activity9</th>\n",
       "      <th>Activity10</th>\n",
       "      <th>Activity11</th>\n",
       "      <th>Activity12</th>\n",
       "      <th>Activity13</th>\n",
       "      <th>Activity14</th>\n",
       "      <th>Activity15</th>\n",
       "      <th>Activity16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>2102.0</td>\n",
       "      <td>3115.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>2958.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Cat_2</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>995.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>3209.0</td>\n",
       "      <td>2617.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>2094.0</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>Cat_10</td>\n",
       "      <td>345.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>457.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>817.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>823.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/1/2018</td>\n",
       "      <td>Cat_2</td>\n",
       "      <td>Cat_10</td>\n",
       "      <td>182.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date CategoricalFeature1 CategoricalFeature2  Activity1  Activity2  \\\n",
       "0  7/1/2018               Cat_1               Cat_1     2102.0     3115.0   \n",
       "1  7/1/2018               Cat_2               Cat_1      995.0      801.0   \n",
       "2  7/1/2018               Cat_4               Cat_1     3209.0     2617.0   \n",
       "3  7/1/2018               Cat_1              Cat_10      345.0      968.0   \n",
       "4  7/1/2018               Cat_2              Cat_10      182.0      196.0   \n",
       "\n",
       "   Target  Activity3  Activity4  Activity5  Activity6  Activity7  Activity8  \\\n",
       "0    52.0     2362.0     1566.0       56.0        NaN        NaN       60.0   \n",
       "1    39.0      941.0      646.0        NaN        NaN        NaN       78.0   \n",
       "2    40.0     3643.0     1292.0       62.0        NaN        NaN      248.0   \n",
       "3     NaN      457.0      842.0        NaN        NaN        NaN      102.0   \n",
       "4    45.0      270.0      435.0        NaN        NaN        NaN       66.0   \n",
       "\n",
       "   Activity9  Activity10  Activity11  Activity12  Activity13  Activity14  \\\n",
       "0      507.0      1031.0      2958.0      2999.0      1800.0      2756.0   \n",
       "1       72.0       310.0       810.0      1123.0       574.0       868.0   \n",
       "2      288.0       583.0      2094.0      2301.0      1342.0      1904.0   \n",
       "3      209.0       817.0      1174.0      1553.0       823.0      1395.0   \n",
       "4       61.0       799.0       695.0       857.0       483.0       706.0   \n",
       "\n",
       "   Activity15  Activity16  \n",
       "0      1038.0        81.0  \n",
       "1       214.0         NaN  \n",
       "2       202.0        48.0  \n",
       "3       185.0        62.0  \n",
       "4       119.0         NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = pd.read_csv('website-eval.csv')\n",
    "eval_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same preprocessing steps will be applied to the holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity1</th>\n",
       "      <th>Activity2</th>\n",
       "      <th>Target</th>\n",
       "      <th>Activity3</th>\n",
       "      <th>Activity4</th>\n",
       "      <th>Activity5</th>\n",
       "      <th>Activity6</th>\n",
       "      <th>Activity7</th>\n",
       "      <th>Activity8</th>\n",
       "      <th>Activity9</th>\n",
       "      <th>Activity10</th>\n",
       "      <th>Activity11</th>\n",
       "      <th>Activity12</th>\n",
       "      <th>Activity13</th>\n",
       "      <th>Activity14</th>\n",
       "      <th>Activity15</th>\n",
       "      <th>Activity16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2102.0</td>\n",
       "      <td>3115.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>2958.0</td>\n",
       "      <td>2999.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2756.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>995.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>941.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>868.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3209.0</td>\n",
       "      <td>2617.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>2094.0</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>1904.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>695.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>973.0</td>\n",
       "      <td>2331.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2065.0</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>629.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>9055.0</td>\n",
       "      <td>6802.0</td>\n",
       "      <td>9827.0</td>\n",
       "      <td>4473.0</td>\n",
       "      <td>8822.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity1  Activity2  Target  Activity3  Activity4  Activity5  Activity6  \\\n",
       "0     2102.0     3115.0    52.0     2362.0     1566.0       56.0        NaN   \n",
       "1      995.0      801.0    39.0      941.0      646.0        NaN        NaN   \n",
       "2     3209.0     2617.0    40.0     3643.0     1292.0       62.0        NaN   \n",
       "4      182.0      196.0    45.0      270.0      435.0        NaN        NaN   \n",
       "5      973.0     2331.0    81.0     2065.0     2563.0       45.0        NaN   \n",
       "\n",
       "   Activity7  Activity8  Activity9  Activity10  Activity11  Activity12  \\\n",
       "0        NaN       60.0      507.0      1031.0      2958.0      2999.0   \n",
       "1        NaN       78.0       72.0       310.0       810.0      1123.0   \n",
       "2        NaN      248.0      288.0       583.0      2094.0      2301.0   \n",
       "4        NaN       66.0       61.0       799.0       695.0       857.0   \n",
       "5        NaN      629.0      301.0      9055.0      6802.0      9827.0   \n",
       "\n",
       "   Activity13  Activity14  Activity15  Activity16  \n",
       "0      1800.0      2756.0      1038.0        81.0  \n",
       "1       574.0       868.0       214.0         NaN  \n",
       "2      1342.0      1904.0       202.0        48.0  \n",
       "4       483.0       706.0       119.0         NaN  \n",
       "5      4473.0      8822.0       647.0        46.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering out missing values in target and filling missings\n",
    "eval_set = eval_set.dropna(subset = ['Target'])\n",
    "\n",
    "to_drop = ['Date', 'CategoricalFeature1', 'CategoricalFeature2']\n",
    "eval_set = eval_set.drop(to_drop, axis=1)\n",
    "\n",
    "eval_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = eval_set.drop('Target',axis=1)\n",
    "y = eval_set.Target\n",
    "\n",
    "deval = xgb.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally predicting and evaluating performance over the holdout set. Results are pretty much in line with what we saw earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.98674648799667\n"
     ]
    }
   ],
   "source": [
    "y_pred_eval = model.predict(deval)\n",
    "\n",
    "# Report testing and training RMSE\n",
    "print(np.sqrt(mean_squared_error(y, y_pred_eval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout = pd.DataFrame({'Target_True': y, 'Target_Pred': y_pred_eval})\n",
    "\n",
    "holdout.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3c_TreeBased_hybrid+SHAP-scores.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
